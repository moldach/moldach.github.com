[{"authors":null,"categories":[],"content":"\rVolcom was founded in 1991, it was the first company to combine skateboarding, surfing and snowboarding under one brand from it’s incepetion. I always loved how their aesthethics captured the energy and artistry of board-riding in its purest form.\nIf you have no idea what I’m talking about here’s some samples from print advertisments and a clip from 2003’s Big Youth Happening which I would say was the ultimate inspiration for this post.\nNon-photorealistic rendering (NPR) is a combination of computer graphics and computer vision that produces renderings in various artistic, expressive or stylized ways. A new art form that couldn’t have existed without computers. Researchers have proposed many algorithms and styles such as painting, pen-and-ink drawing, tile mosaics, stippling, streamline visualization, and tensor field visualization. Although the details vary, the goal is to make an image look like some other image. Two main approaches to designing these algorithms exist. Greedy algorithms greedily place strokes to match the target goas. Optimization algorithms iteratively place and then adjust stroke positions to minimize the objective function. NPR can be done using a number of machine learning methods, most commonly General Adverserial Networks or Convolution Neural Networks(CNN).\rsuch as painting and drawing.\nI wanted to use lengstrom/fast-style-transfer, an optimization technique, on a video of my friends and I backcountry skiing and snowboarding in The Rocky Mountains of Alberta.\nFast-style-transfer is a TensorFlow CNN model based on a combination of Gatys’ A Neural Algorithm of Artistic Style, Johnson’s Perceptual Losses for Real-Time Style Transfer and Super-Resolution, and Ulyanov’s Instance Normalization. I’ll skip the details here because it’s been been far better described in the publications above (or in layman’s terms here, here, and here), suffice it to say it allows you to compose images/videos in the style of another image. Besides being fun it’s a nice visual way of showing the capabilities and internal representations of neural networks.\nfast-style-transfer repo comes with 6 trained models on famous paintings, allowing you to quikcly style your images (or videos) like them. But what’s the fun in doing what others have alread done?\nI wanted to see what kind of effect would be produced by training style transfer networks around interesting shapes and patterns! I selected a number patterns I thought would be interesting, for example animal patterns, fractals, fibonnaci sequences, a few vaporwave images (of course), and a bunch of images taken under a SEM microscope.\nI then constructed a script to train 50 models simultaneously on a HPC (using a GPU NVIDIA V100 Volta; a top-of-the-line $10,000 GPU - spared no expense). After many many hours of training, across hundreds of cores, I selected the 20 best (i.e. most aesthetically pleasing) models to apply to the video.\n(The entire high-quality video can be found here](https://youtu.be/TuN4456PK-c).\nTechnical Notes:\rWhen training the models I noticed that the checkpoint files were being corrupted. I found a closed issue on the repo: #78 stating that Tensorflow’s Saver class was updated so you’ll need to change line 136 in /src/optimize.py.\nThe script for training all of the networks on an HPC with a SLURM job scheduler is below, and can be run with bash fastTrainer.bash \u0026lt;image_path\u0026gt; \u0026lt;out_path\u0026gt; \u0026lt;test_path\u0026gt;. Simply clone lengstrom/fast-style-transfer and create three folders inside. Create a sub-directory where you’ll put all the style images you want to train, another sub-directory for the output (.ckpt files used to style your .mp4 videos), and a test sub-directory for the model. As a default I used the chicago for training and I’m not entirely sure if that makes a difference.\n!/bin/bash\r#$ -pwd\r# bash fastTrainer.bash /images/ /outpath/ /testpath/\r##\r## An embarrassingly parallel script to train many style transfer networks on a HPC\r## Access to SLURM job scheduler and fast-style-transfer is required to run this program.\r## The three mandatory pathways must be specified in the indicated order.\rIMG=$(readlink -f \u0026quot;${1%/}\u0026quot;) # path_to_train_images\rOUT_DIR=$(readlink -f \u0026quot;${2%/}\u0026quot;) # path_to_checkpoints\rTEST=$(readlink -f \u0026quot;${3%/}\u0026quot;) # path_to_tests\rmkdir -p ${OUT_DIR}/jobs\rJID=0 # job ID for SLURM job name\rfor f in ${IMG}/*; do\rlet JID=(JID+1)\rcat \u0026gt; ${OUT_DIR}/jobs/style_${JID}.bash \u0026lt;\u0026lt; EOT # write job information for each job\r#!/bin/bash\r#SBATCH --gres=gpu:1 # request GPU\r#SBATCH --cpus-per-task=2 # maximum CPU cores per GPU request\r#SBATCH --time=00:01:00 # request 8 hours of walltime\r#SBATCH --job-name=\u0026quot;fst_${JID}\u0026quot;\r#SBATCH --output=${OUT_DIR}/jobs/%N-%j.out # %N for node name, %j for jobID\r### JOB SCRIPT BELLOW ###\r# Load Modules\rmodule load python/2.7.14\rmodule load scipy-stack\rsource tensorflow/bin/activate\rmkdir ${OUT_DIR}/${JID}\rmkdir ${TEST}/${JID}\rpython style.py --style $f \\\r--checkpoint-dir ${OUT_DIR}/${JID} \\\r--test examples/content/chicago.jpg \\\r--test-dir ${OUT_DIR}/${JID} \\\r--content-weight 1.5e1 \\\r--checkpoint-iterations 1000 \\\r--batch-size 20\rEOT\rchmod 754 $(readlink -f \u0026quot;${OUT_DIR}\u0026quot;)/jobs/style_${JID}.bash\rsbatch $(readlink -f \u0026quot;${OUT_DIR}\u0026quot;)/jobs/style_${JID}.bash\rdone\r\r\rWhat I learned\rNow Sean Dorrance Kelly might argue I’m using the machines “creativity” as a subsititute for my own but I would disagree since there was a fair amount of creativity in selecting images to train models on and the editing itself. That being said an AI generated work of art recently sold for $432,500 at Christie’s (the first auction house to offer a piece of art created by an algorithm).\nBesides the opportunity to exercise my right-brain, it was a good chance to gain some experience with tensorflow and python. This project was also illuminating because it made the hidden layers of networks more comprehensible by literally allowing me to see how neural networks are performing!\nI think the field of Feature visualization is exciting because it allows to peer behind the curtain and see how networks learn to classify images accurately. Take for example the Activation atlas which reveals visual abstractions within a model. It gives a global view of a dataset by showing feature visualization of averaged activation values from a neural network.\n\rAs an analogy, while the 26 letters in the alphabet provide a basis for English, seeing how letters are commonly combined to make words gives far more insight into the concepts that can be expressed than the letters alone. Similarly, activation atlases give us a bigger picture view by showing common combinations of neurons.\n\rIn a perfect world the artist/user should have control over the decisions made by the algorithm. For example, to specify spatially varying styles to use, so that different rendering styles are used in different parts of the image, or to specify positions of individuial strokes. However, training these models is still too slow to be useful in an interactive application.\n\r","date":1555804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555804800,"objectID":"fc222b3520f2e6cfaae1d747f9cad16f","permalink":"/post/tensorflow-cnn-for-fast-style-transfer/","publishdate":"2019-04-21T00:00:00Z","relpermalink":"/post/tensorflow-cnn-for-fast-style-transfer/","section":"post","summary":"Volcom was founded in 1991, it was the first company to combine skateboarding, surfing and snowboarding under one brand from it’s incepetion. I always loved how their aesthethics captured the energy and artistry of board-riding in its purest form.\nIf you have no idea what I’m talking about here’s some samples from print advertisments and a clip from 2003’s Big Youth Happening which I would say was the ultimate inspiration for this post.","tags":[],"title":"TensorFlow CNN for Fast Style Transfer","type":"post"},{"authors":["Matthew J. Oldach"],"categories":[],"content":" Volcom was founded in 1991, it was the first company to combine skateboarding, surfing and snowboarding under one brand from it\u0026rsquo;s incepetion. I always loved how their aesthethics captured the energy and artistry of board-riding in its purest form.\nIf you have no idea what I\u0026rsquo;m talking about here\u0026rsquo;s some samples from print advertisments and a clip from 2003\u0026rsquo;s Big Youth Happening which I would say was the ultimate inspiration for this post.\nNon-photorealistic rendering (NPR) is a combination of computer graphics and computer vision that produces renderings in various artistic, expressive or stylized ways. A new art form that couldn\u0026rsquo;t have existed without computers. Researchers have proposed many algorithms and styles such as painting, pen-and-ink drawing, tile mosaics, stippling, streamline visualization, and tensor field visualization. Although the details vary, the goal is to make an image look like some other image. Two main approaches to designing these algorithms exist. Greedy algorithms greedily place strokes to match the target goas. Optimization algorithms iteratively place and then adjust stroke positions to minimize the objective function. NPR can be done using a number of machine learning methods, most commonly General Adverserial Networks or Convolution Neural Networks(CNN). such as painting and drawing.\nI wanted to use lengstrom/fast-style-transfer, an optimization technique, on a video of my friends and I backcountry skiing and snowboarding in The Rocky Mountains of Alberta.\nFast-style-transfer is a TensorFlow CNN model based on a combination of Gatys\u0026rsquo; A Neural Algorithm of Artistic Style, Johnson\u0026rsquo;s Perceptual Losses for Real-Time Style Transfer and Super-Resolution, and Ulyanov\u0026rsquo;s Instance Normalization. I\u0026rsquo;ll skip the details here because it\u0026rsquo;s been been far better described in the publications above (or in layman\u0026rsquo;s terms here, here, and here), suffice it to say it allows you to compose images/videos in the style of another image. Besides being fun it\u0026rsquo;s a nice visual way of showing the capabilities and internal representations of neural networks.\nfast-style-transfer repo comes with 6 trained models on famous paintings, allowing you to quikcly style your images (or videos) like them. But what\u0026rsquo;s the fun in doing what others have alread done?\nI wanted to see what kind of effect would be produced by training style transfer networks around interesting shapes and patterns! I selected a number patterns I thought would be interesting, for example animal patterns, fractals, fibonnaci sequences, a few vaporwave images (of course), and a bunch of images taken under a SEM microscope.\nI then constructed a script to train 50 models simultaneously on a HPC (using a GPU NVIDIA V100 Volta; a top-of-the-line $10,000 GPU - spared no expense). After many many hours of training, across hundreds of cores, I selected the 20 best (i.e. most aesthetically pleasing) models to apply to the video.\n(The entire high-quality video can be found here](https://youtu.be/TuN4456PK-c).\nTechnical Notes: When training the models I noticed that the checkpoint files were being corrupted. I found a closed issue on the repo: #78 stating that Tensorflow\u0026rsquo;s Saver class was updated so you\u0026rsquo;ll need to change line 136 in /src/optimize.py.\nThe script for training all of the networks on an HPC with a SLURM job scheduler is below, and can be run with bash fastTrainer.bash \u0026lt;image_path\u0026gt; \u0026lt;out_path\u0026gt; \u0026lt;test_path\u0026gt;. Simply clone lengstrom/fast-style-transfer and create three folders inside. Create a sub-directory where you\u0026rsquo;ll put all the style images you want to train, another sub-directory for the output (.ckpt files used to style your .mp4 videos), and a test sub-directory for the model. As a default I used the chicago for training and I\u0026rsquo;m not entirely sure if that makes a difference.\n!/bin/bash #$ -pwd # bash fastTrainer.bash /images/ /outpath/ /testpath/ ## ## An embarrassingly parallel script to train many style transfer networks on a HPC ## Access to SLURM job scheduler and fast-style-transfer is required to run this program. ## The three mandatory pathways must be specified in the indicated order. IMG=$(readlink -f \u0026quot;${1%/}\u0026quot;) # path_to_train_images OUT_DIR=$(readlink -f \u0026quot;${2%/}\u0026quot;) # path_to_checkpoints TEST=$(readlink -f \u0026quot;${3%/}\u0026quot;) # path_to_tests mkdir -p ${OUT_DIR}/jobs JID=0 # job ID for SLURM job name for f in ${IMG}/*; do let JID=(JID+1) cat \u0026gt; ${OUT_DIR}/jobs/style_${JID}.bash \u0026lt;\u0026lt; EOT # write job information for each job #!/bin/bash #SBATCH --gres=gpu:1 # request GPU #SBATCH --cpus-per-task=2 # maximum CPU cores per GPU request #SBATCH --time=00:01:00 # request 8 hours of walltime #SBATCH --job-name=\u0026quot;fst_${JID}\u0026quot; #SBATCH --output=${OUT_DIR}/jobs/%N-%j.out # %N for node name, %j for jobID ### JOB SCRIPT BELLOW ### # Load Modules module load python/2.7.14 module load scipy-stack source tensorflow/bin/activate mkdir ${OUT_DIR}/${JID} mkdir ${TEST}/${JID} python style.py --style $f \\ --checkpoint-dir ${OUT_DIR}/${JID} \\ --test examples/content/chicago.jpg \\ --test-dir ${OUT_DIR}/${JID} \\ --content-weight 1.5e1 \\ --checkpoint-iterations 1000 \\ --batch-size 20 EOT chmod 754 $(readlink -f \u0026quot;${OUT_DIR}\u0026quot;)/jobs/style_${JID}.bash sbatch $(readlink -f \u0026quot;${OUT_DIR}\u0026quot;)/jobs/style_${JID}.bash done  What I learned Now Sean Dorrance Kelly might argue I\u0026rsquo;m using the machines \u0026ldquo;creativity\u0026rdquo; as a subsititute for my own but I would disagree since there was a fair amount of creativity in selecting images to train models on and the editing itself. That being said an AI generated work of art recently sold for $432,500 at Christie\u0026rsquo;s (the first auction house to offer a piece of art created by an algorithm).\nBesides the opportunity to exercise my right-brain, it was a good chance to gain some experience with tensorflow and python. This project was also illuminating because it made the hidden layers of networks more comprehensible by literally allowing me to see how neural networks are performing!\nI think the field of Feature visualization is exciting because it allows to peer behind the curtain and see how networks learn to classify images accurately. Take for example the Activation atlas which reveals visual abstractions within a model. It gives a global view of a dataset by showing feature visualization of averaged activation values from a neural network.\n As an analogy, while the 26 letters in the alphabet provide a basis for English, seeing how letters are commonly combined to make words gives far more insight into the concepts that can be expressed than the letters alone. Similarly, activation atlases give us a bigger picture view by showing common combinations of neurons.\n In a perfect world the artist/user should have control over the decisions made by the algorithm. For example, to specify spatially varying styles to use, so that different rendering styles are used in different parts of the image, or to specify positions of individuial strokes. However, training these models is still too slow to be useful in an interactive application.\n","date":1555804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555804800,"objectID":"4c9587f5d30f42fac519d583f09a80f1","permalink":"/post/faststyletransfer/","publishdate":"2019-04-21T00:00:00Z","relpermalink":"/post/faststyletransfer/","section":"post","summary":"Volcom was founded in 1991, it was the first company to combine skateboarding, surfing and snowboarding under one brand from it\u0026rsquo;s incepetion. I always loved how their aesthethics captured the energy and artistry of board-riding in its purest form.\nIf you have no idea what I\u0026rsquo;m talking about here\u0026rsquo;s some samples from print advertisments and a clip from 2003\u0026rsquo;s Big Youth Happening which I would say was the ultimate inspiration for this post.","tags":[],"title":"TensorFlow CNN for Fast Style Transfer","type":"post"},{"authors":["Matthew J. Oldach"],"categories":[],"content":" Just as test automation is a critical part of rutheless testing, your goal for any project should be to identify taks that can be automated (and do it!).\nThere are a number of packages that allow you to schedule R scripts at specific times; two that come to mind are taskscheduleR (for Windows) and cronR (for Unix/Linux). We have cronR setup on RStudio server at work, and it has a nice RStudio addin which allows us to schedule tasks around any complex schedule. You can use these kind of tools to automate data collections, automate markdown reports to e-mail, or even the weather.\nAlternatively, when you want a function (or script) to launch every time you start R you can place these inside .Rprofile.\nBut what about if you want a function to start only the first time a user logs in? This could be something simple (like a reminder) to fill in a progress report, or in this case a bit of Monday Morning (de)Motivation. This is a job for logfiles!\nLet\u0026rsquo;s be straight here, I love Mondays (because rweekly is released!), but most people don\u0026rsquo;t! Therefore, I made a .csv file of 178 quotes about Monday and a folder of 83 .png images of cartoon characters sleeping. I used the .First() function in .Rprofile to create a logfile (if one doesn\u0026rsquo;t already exist) and randomly pair an image with a quote the first time a user logs in on Monday morning (using the advicegiveR package). Here\u0026rsquo;s some examples of images a user might see first thing Monday morning:\nThe Good The Bad The Ugly Any other time of that day (or any other day of the week) it will simply call a sage piece of collected advice from the R-help forum via the fortunes package. An example:\n R will always be arcane to those who do not make a serious effort to learn it. It is not meant to be intuitive and easy for casual users to just plunge into. It is far too complex and powerful for that. But the rewards are great for serious data analysts who put in the effort. \u0026ndash; Berton Gunter R-help (August 2007)\n You need to create a folder in your home directory that contains a quotes.csv, a LogFile.txt and images folder.\n.First \u0026lt;- function(){ today \u0026lt;- as.Date(Sys.Date()) LastLog \u0026lt;- \u0026quot;\u0026quot; if(file.exists(\u0026quot;~/iHateMondays/LogFile.txt\u0026quot;)) { LogFile \u0026lt;- file(\u0026quot;~/iHateMondays/LogFile.txt\u0026quot;, open=\u0026quot;r\u0026quot;) LastLog \u0026lt;- readLines(LogFile, 1L) close(LogFile) } LogFile \u0026lt;- file(\u0026quot;~/iHateMondays/LogFile.txt\u0026quot;, open=\u0026quot;w\u0026quot;) writeLines(as.character(today), LogFile) close(LogFile) if(LastLog == as.character(today)) { # Already logged on today, just exit return() } ## If you get here, Need to run the first login code DOW \u0026lt;- weekdays(today) if (DOW == \u0026quot;Monday\u0026quot;) { # I Hate Mondays! suppressWarnings(library(advicegiveR, warn.conflicts = FALSE)) suppressWarnings(library(readr, warn.conflicts = FALSE)) quotes \u0026lt;- read_csv(\u0026quot;~/iHateMondays/quotes.csv\u0026quot;, col_names = FALSE) x1 \u0026lt;- sample(1:nrow(quotes), 1) advice \u0026lt;- as.character(quotes[x1,]) y \u0026lt;- list.files(\u0026quot;~/iHateMondays/images\u0026quot;) # select one randomly y1 \u0026lt;- sample(1:length(y), 1) image \u0026lt;- magick::image_read(paste0(\u0026quot;~/iHateMondays/images\u0026quot;, y[y1])) # print image advicegiveR::print_advice(image = image, advice = advice, textcolor = \u0026quot;yellow\u0026quot;, size = 40) } else { # Fortune suppressWarnings(library(fortunes, warn.conflicts = FALSE)) rnum \u0026lt;- sample(1:386, 1) print(fortune(rnum)) } }  Now Ideally, you should use a contrasting border around the inner text color to make it readable on any background.\nThe meme R package package uses a black border around text and positions text like a typical meme (top \u0026amp; bottom).\nBy including a simple helper function to split the quote into equal lengthed top/bottom sections, the code would look like this:\n pre.bluecars { background-color: #aabbff !important; } pre.redcars { background-color: #ffbbbb !important; }  suppressWarnings(library(tidyverse)) word_split \u0026lt;- function(x, side=\u0026quot;left\u0026quot;, sep=\u0026quot; \u0026quot;) { words \u0026lt;- strsplit(as.character(x), sep) nwords \u0026lt;- lengths(words) if(side==\u0026quot;left\u0026quot;) { start \u0026lt;- 1 end \u0026lt;- ceiling(nwords/2) } else if (side==\u0026quot;right\u0026quot;) { start \u0026lt;- ceiling((nwords+2)/2) end \u0026lt;- nwords } cw \u0026lt;- function(words, start, stop) paste(words[start:stop], collapse=sep) pmap_chr(list(words, start, end), cw) } left_words \u0026lt;- function(..., side) word_split(..., side=\u0026quot;left\u0026quot;) right_words \u0026lt;- function(..., side) word_split(..., side=\u0026quot;right\u0026quot;) .First \u0026lt;- function(){ today \u0026lt;- as.Date(Sys.Date()) LastLog \u0026lt;- \u0026quot;\u0026quot; if(file.exists(\u0026quot;~/iHateMondays/LogFile.txt\u0026quot;)) { LogFile \u0026lt;- file(\u0026quot;~/iHateMondays/LogFile.txt\u0026quot;, open=\u0026quot;r\u0026quot;) LastLog \u0026lt;- readLines(LogFile, 1L) close(LogFile) } LogFile \u0026lt;- file(\u0026quot;~/iHateMondays/LogFile.txt\u0026quot;, open=\u0026quot;w\u0026quot;) writeLines(as.character(today), LogFile) close(LogFile) if(LastLog == as.character(today)) { # Already logged on today, just exit return() } ## If you get here, Need to run the first login code DOW \u0026lt;- weekdays(today) if (DOW == \u0026quot;Monday\u0026quot;) { # I Hate Mondays! suppressWarnings(library(readr, warn.conflicts = FALSE)) suppressWarnings(library(meme, warn.conflicts = FALSE)) quotes \u0026lt;- read_csv(\u0026quot;~/iHateMondays/quotes.csv\u0026quot;, col_names = FALSE) x1 \u0026lt;- sample(1:nrow(quotes), 1) advice \u0026lt;- as.character(quotes[x1,]) top_words \u0026lt;- left_words(advice) bottom_words \u0026lt;- right_words(advice) y \u0026lt;- list.files(\u0026quot;~/iHateMondays/images\u0026quot;) # select one randomly y1 \u0026lt;- sample(1:length(y), 1) image \u0026lt;- magick::image_read(paste0(\u0026quot;~/iHateMondays/images/\u0026quot;, y[y1])) # print image meme(paste0(\u0026quot;~/iHateMondays/images/\u0026quot;, y[y1]), size = \u0026quot;1.5\u0026quot;, upper = top_words, lower = bottom_words, color = \u0026quot;yellow\u0026quot;, font = \u0026quot;Times\u0026quot;) } else { # Fortune suppressWarnings(library(fortunes, warn.conflicts = FALSE)) rnum \u0026lt;- sample(1:386, 1) print(fortune(rnum)) } }  ","date":1554163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554163200,"objectID":"31f1aaa0b75abc4e94d1429a8a81fffd","permalink":"/post/rprofile/","publishdate":"2019-04-02T00:00:00Z","relpermalink":"/post/rprofile/","section":"post","summary":"Just as test automation is a critical part of rutheless testing, your goal for any project should be to identify taks that can be automated (and do it!).\nThere are a number of packages that allow you to schedule R scripts at specific times; two that come to mind are taskscheduleR (for Windows) and cronR (for Unix/Linux). We have cronR setup on RStudio server at work, and it has a nice RStudio addin which allows us to schedule tasks around any complex schedule.","tags":[],"title":"Step aside Cron, this is a job for .Rprofile \u0026 logfiles!","type":"post"},{"authors":["Matthew J. Oldach"],"categories":[],"content":"A graduate student in our laboratory recently asked me if it was possible to include more than two images, side-by-side, in Xaringan.\nOf course anything is possible, however, most blog posts only touch on the most basic things you can do. With custom CSS you can do whatever you want. I wanted to create an image-grid of a bunch of GIFs so I used the ninjutsu theme to accomplish it.\nLink to the slide-show\n","date":1551916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551916800,"objectID":"2efca2fb9187e578af4186ab31b47cc0","permalink":"/post/ninjutsu/","publishdate":"2019-03-07T00:00:00Z","relpermalink":"/post/ninjutsu/","section":"post","summary":"A graduate student in our laboratory recently asked me if it was possible to include more than two images, side-by-side, in Xaringan.\nOf course anything is possible, however, most blog posts only touch on the most basic things you can do. With custom CSS you can do whatever you want. I wanted to create an image-grid of a bunch of GIFs so I used the ninjutsu theme to accomplish it.","tags":[],"title":"Image-grid with Ninjutsu CSS theme in Xaringan","type":"post"},{"authors":["Matthew J. Oldach"],"categories":[],"content":"Recently I got interested in using the xaringan package for creating HTML based R Markdown documents because I could use the widgetframe package to embed htmlwidgets as responsive iframes (I had created some spinning 3D visulizations with pseudo-coloring I wanted to present interactively).\nxaringan, it\u0026rsquo;s a R pacakges for creating slideshows with remark.js through R Markdown.\nAround the same time I learnt about Drake (or \u0026ldquo;Data Frames in R for Make\u0026rdquo;) which is an amazing a time-saving reproducible build system for data scientist specifically tailored to R. The pacakge makes use of the futures package allowing the use of parallel computing on high-performance computing systems.\nI recently gave a talk at the Douglas Mental Health University Institute talking about the advantages of Drake (and a few other interesting projects).\nThe slides can be found here\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"d020517875ffc995fcc285f4429ea0dc","permalink":"/post/drake/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/drake/","section":"post","summary":"Recently I got interested in using the xaringan package for creating HTML based R Markdown documents because I could use the widgetframe package to embed htmlwidgets as responsive iframes (I had created some spinning 3D visulizations with pseudo-coloring I wanted to present interactively).\nxaringan, it\u0026rsquo;s a R pacakges for creating slideshows with remark.js through R Markdown.\nAround the same time I learnt about Drake (or \u0026ldquo;Data Frames in R for Make\u0026rdquo;) which is an amazing a time-saving reproducible build system for data scientist specifically tailored to R.","tags":[],"title":"Getting Started with Drake in R","type":"post"},{"authors":null,"categories":null,"content":"","date":1548910800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548910800,"objectID":"828c433ee6b2db0f7e6e716e0ebea6b8","permalink":"/project/rselenium/","publishdate":"2019-01-31T00:00:00-05:00","relpermalink":"/project/rselenium/","section":"project","summary":"","tags":["R","Selenium","Web Scraping"],"title":"Web Scraping Google Sheets with RSelenium","type":"project"},{"authors":null,"categories":null,"content":"","date":1548824400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548824400,"objectID":"9509e359b6487091879d5b2a922ccaf3","permalink":"/project/optimal-clustering/","publishdate":"2019-01-30T00:00:00-05:00","relpermalink":"/project/optimal-clustering/","section":"project","summary":"","tags":["R","unsupervised learning","clustering","dataviz"],"title":"10 Tips for Choosing the Optimal Number of Clusters","type":"project"},{"authors":null,"categories":null,"content":"","date":1541826000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541826000,"objectID":"07638dd7098574f6d189725766120e37","permalink":"/project/fitbit-project/","publishdate":"2018-11-10T00:00:00-05:00","relpermalink":"/project/fitbit-project/","section":"project","summary":"Accessing biometric data from the Fitbit API","tags":["Demo"],"title":"The Gamification of Fitbit: How An API Provided The Next Level of tRaining","type":"project"},{"authors":null,"categories":null,"content":"","date":1540958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540958400,"objectID":"33e2f22744f7ffc90b6608034faa6d64","permalink":"/project/3d-brain/","publishdate":"2018-10-31T00:00:00-04:00","relpermalink":"/project/3d-brain/","section":"project","summary":"A tutorial for three methods of labelling an ROI in brain images","tags":["R","MATLAB","dataviz"],"title":"How to Highlight 3D Brain Regions","type":"project"},{"authors":null,"categories":null,"content":"","date":1540958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540958400,"objectID":"5c81a4c93facf0146bee152ce4445125","permalink":"/project/assembly/","publishdate":"2018-10-31T00:00:00-04:00","relpermalink":"/project/assembly/","section":"project","summary":"Transcriptome Assembly and Annotation.","tags":["R","MATLAB","dataviz"],"title":"Transcriptome Assembly and Annotation","type":"project"},{"authors":null,"categories":null,"content":"","date":1540958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540958400,"objectID":"15b770d7945e057af25b70575d2a17d2","permalink":"/project/vaporwave/","publishdate":"2018-10-31T00:00:00-04:00","relpermalink":"/project/vaporwave/","section":"project","summary":"This package provides a number of ggplot2 themes inspired by vaporwave, both a subgenre of electronic music and an art movement.","tags":["R","MATLAB","dataviz"],"title":"vapoRwave ggplot2 themes \u0026 palettes","type":"project"},{"authors":null,"categories":null,"content":"","date":1538798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538798400,"objectID":"10c51808100a791168172f28e1665396","permalink":"/project/software-solutions/","publishdate":"2018-10-06T00:00:00-04:00","relpermalink":"/project/software-solutions/","section":"project","summary":"How to Choose the Best Open Source Software","tags":["R","Linux"],"title":"How to Choose the Best Open Source Software","type":"project"},{"authors":null,"categories":null,"content":"","date":1538798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538798400,"objectID":"ac51ee586d1e4b697548c53785cb3906","permalink":"/project/reverse-axis/","publishdate":"2018-10-06T00:00:00-04:00","relpermalink":"/project/reverse-axis/","section":"project","summary":"Playing around with the axis display in ggplot2","tags":["R","dataviz","ggplot2"],"title":"Reversing the order of axis in a ggplot2 scatterplot","type":"project"},{"authors":null,"categories":null,"content":"","date":1538798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538798400,"objectID":"9d9c34ceb8b0c1a50201ee433eeea314","permalink":"/project/project-management/","publishdate":"2018-10-06T00:00:00-04:00","relpermalink":"/project/project-management/","section":"project","summary":"Gold Standard workflow for setting up a new data science project directory and file naming","tags":["R","Linux"],"title":"The Gold Standard for Data Science Project Management","type":"project"},{"authors":null,"categories":null,"content":"","date":1528257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528257600,"objectID":"50849994ea21f115ab228a5a65e77f98","permalink":"/project/knowledge-is-beautiful/","publishdate":"2018-06-06T00:00:00-04:00","relpermalink":"/project/knowledge-is-beautiful/","section":"project","summary":"In this series I will set out to recreate some of the visualization from the book “Knowledge is Beautiful” by David McCandless in R.","tags":["Demo"],"title":"Recreating data visualizations from the book Knowledge is Beautiful","type":"project"},{"authors":null,"categories":null,"content":"","date":1525665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525665600,"objectID":"8ea76530e4d2b23df61593c667b88517","permalink":"/project/free-ride-world-tour/","publishdate":"2018-05-07T00:00:00-04:00","relpermalink":"/project/free-ride-world-tour/","section":"project","summary":"Using the TwitteR package and web-scraping the FWT website for better insights","tags":["R","Web scraping","dataviz","API"],"title":"Analyzing 12 years of the Free Ride World Tour","type":"project"},{"authors":null,"categories":null,"content":"","date":1520658000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520658000,"objectID":"44d9666beba54e6a51f6b1436dc8c31a","permalink":"/project/gsea/","publishdate":"2018-03-10T00:00:00-05:00","relpermalink":"/project/gsea/","section":"project","summary":"Techniques for the analysis of gene set enrichments, pathway analysis, gene ontologies, functional analysis of metabolomic profiling and coexpression networks","tags":["R","dataviz","ggplot2"],"title":"Gene set enrichment in R","type":"project"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483246800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483246800,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00-05:00","relpermalink":"/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"}]