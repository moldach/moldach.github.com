<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matthew J. Oldach on Matthew J. Oldach</title>
    <link>/</link>
    <description>Recent content in Matthew J. Oldach on Matthew J. Oldach</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Thoughts on building Shiny applications, Software Release Cycles and Rayshader</title>
      <link>/project/hinuhinu/hinuhinu/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/hinuhinu/hinuhinu/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;walkthrough.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://matthew-j-oldach.shinyapps.io/hinuhinu&#34; target=&#34;_blank&#34;&gt;CLICK HERE TO GO TO THE SHINY APPLICATION!!!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;inspiration-for-the-shiny-application&#34;&gt;Inspiration for the Shiny Application&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;You can read as much theory as you want but the best way to learn something is to pull-up your sleeves and get your hands dirty by implementing a project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;ve been wanting to develop a &lt;a href=&#34;https://shiny.rstudio.com/&#34; target=&#34;_blank&#34;&gt;Shiny application&lt;/a&gt; for sometime but the opportunity never arose. In my current role as a &lt;strong&gt;R&lt;/strong&gt; developer, I provide client-side implementations via &lt;strong&gt;Java&lt;/strong&gt; with the help of the &lt;code&gt;RServe&lt;/code&gt; 📦 - so Shiny isn&amp;rsquo;t needed. If say, if the opportunity doesn&amp;rsquo;t present itself on the job it&amp;rsquo;s time for a side-project!&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;I wasn&amp;rsquo;t exactly sure what kind of project I should do until I saw a blog post by &lt;a href=&#34;https://timogrossenbacher.ch/&#34; target=&#34;_blank&#34;&gt;Timo Grossenbacher&lt;/a&gt; on &lt;a href=&#34;https://timogrossenbacher.ch/2019/04/bivariate-maps-with-ggplot2-and-sf/&#34; target=&#34;_blank&#34;&gt;bivariate maps with &lt;code&gt;ggplot2&lt;/code&gt; and &lt;code&gt;sf&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;swiss.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;The map shows income (in-)equality in Switzerland at the municipality level by visualizing two variables at the same time. What instantly attracted me was the beautiful relief of the mountainous Swiss landscape. It&amp;rsquo;s not something I&amp;rsquo;ve seen much from &lt;code&gt;ggplot2&lt;/code&gt; maps - something usually reserved for GIS programs. I thought creating an application for geography would be a fun and engaging use of a Shiny application. My current role as a developer for a web-application that enables complex meta-analysis and visualization caters to biologists rather than specilazied bioinformaticians- &lt;a href=&#34;https://www.networkanalyst.ca/&#34; target=&#34;_blank&#34;&gt;NetworkAnalyst.ca&lt;/a&gt;. I thought it might be cool to do a similar thing for people who are not cartographers or GIS specialists (or even familiar with &lt;code&gt;R&lt;/code&gt;) and enable them to quickly create maps and save them (either as &lt;code&gt;PNGs&lt;/code&gt; or &lt;code&gt;PDFs&lt;/code&gt;)?&lt;/p&gt;

&lt;p&gt;One of the intial challanges was finding a good dataset. I had wanted to intially start with my home province of Alberta but eventually settled on Hawaii instead for a couple reasons. One is that I could find &lt;a href=&#34;https://geo.nyu.edu&#34; target=&#34;_blank&#34;&gt;relief&amp;rsquo;s for the State of Hawaii&lt;/a&gt; in two levels of detail: &lt;strong&gt;100m&lt;/strong&gt; and &lt;strong&gt;200m&lt;/strong&gt;. The second was the State of Hawaii &lt;a href=&#34;https://planning.hawaii.gov/gis/download-gis-data/&#34; target=&#34;_blank&#34;&gt;also provides a &lt;strong&gt;large&lt;/strong&gt; number of shapefiles&lt;/a&gt; which I could lay overtop of the relief. The amount of open data available to Hawaii attractive, and the fact that they are islands presented certain opportunities&amp;hellip; and challenges, as well.&lt;/p&gt;

&lt;p&gt;I wanted to provide users with a range maps. I wanted maps at different scales and with different contexts such as focusing on the marine environment or the terrestrial enviornment. I wanted maps covering the whole state of Hawaii, others showing individual islands (or groups of islands), and others giving the user a view of the city level. It was here that I got inspiration from &lt;a href=&#34;erdavis.com&#34; target=&#34;_blank&#34;&gt;Erin Davis&amp;rsquo;s&lt;/a&gt; beautiful street maps in &lt;a href=&#34;https://erdavis.com/2019/09/20/the-beautiful-hidden-logic-of-cities-worldwide/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;The Beatiful Hidden Logic of Cities - Worldwide&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;paris.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Erin&amp;rsquo;s legend looked great! Unfortunately she didn&amp;rsquo;t have a programatic way to generate these labels, she did them in Adobe Photoshop (&lt;em&gt;personal correspondence&lt;/em&gt;). I tried to write some code to generate labels programattically using &lt;code&gt;key_glyph = &amp;quot;point&amp;quot;&lt;/code&gt; to set &lt;code&gt;sf&lt;/code&gt; object glyphs as points and then use the &lt;code&gt;override.aes&lt;/code&gt; trick to get circles (&lt;a href=&#34;https://stackoverflow.com/questions/58172102/dynamically-align-plots-custom-ggplot2-legend-for-spatial-maps-in-r&#34; target=&#34;_blank&#34;&gt;like in this SO post&lt;/a&gt; post) but I didn&amp;rsquo;t like the look. To be honest lables are something that could still use work in the &lt;code&gt;ggplot2&lt;/code&gt; world IMO 🤷&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/jakekaupp&#34; target=&#34;_blank&#34;&gt;Jake Kaupp&lt;/a&gt; did a &lt;code&gt;#TidyTuesday&lt;/code&gt; submission for &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-10-01&#34; target=&#34;_blank&#34;&gt;Week #40: Pizza Party!&lt;/a&gt; showing all of the pizza spots in the five-boroughs and came up with a nice way of &lt;a href=&#34;https://github.com/jkaupp/tidytuesdays/blob/master/2019/week40/R/analysis.R&#34; target=&#34;_blank&#34;&gt;constructing a color legend with &lt;code&gt;ggplotGrob()&lt;/code&gt;&lt;/a&gt; as well as a neat use of &lt;a href=&#34;https://cran.r-project.org/web/packages/colorspace/vignettes/colorspace.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;colorspace::darken()&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;pizza.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;For Shiny &lt;strong&gt;UI&lt;/strong&gt; inspiration I looked towards some of the &lt;a href=&#34;https://blog.rstudio.com/2019/04/05/first-shiny-contest-winners/&#34; target=&#34;_blank&#34;&gt;winners of the 1st ever Shiny Contest  &lt;/a&gt; (something I hope RStudio brings back next year!). I can&amp;rsquo;t express how much I learn from reading other peoples code and for this particular application I was heavily inspired by the &lt;a href=&#34;https://community.rstudio.com/u/committedtotape/&#34; target=&#34;_blank&#34;&gt;David Smale&lt;/a&gt;&amp;rsquo;s, winner of &lt;strong&gt;&amp;ldquo;Best Design&amp;rdquo;&lt;/strong&gt;, &lt;a href=&#34;https://committedtotape.shinyapps.io/sixtyninelovesongs/&#34; target=&#34;_blank&#34;&gt;69 Love Songs: A Lyrical Analysis&lt;/a&gt;. What was really cool was it was hosted on the RStudio cloud so I could go in and change things and see how it affected which for me was one of the coolest ways to grok Shiny.&lt;/p&gt;

&lt;h2 id=&#34;building-the-application&#34;&gt;Building the application&lt;/h2&gt;

&lt;p&gt;Getting back to elevation reliefs for a second. Before I learned that you could &lt;em&gt;easily&lt;/em&gt; get &lt;strong&gt;Digital Elevation Model&lt;/strong&gt; (DEM) data from &lt;code&gt;mapzen&lt;/code&gt; via the {&lt;a href=&#34;https://github.com/neilcharles/geoviz&#34; target=&#34;_blank&#34;&gt;`geoviz&amp;rsquo;&lt;/a&gt;} 📦, I used &lt;a href=&#34;https://www.qgis.org/en/site/&#34; target=&#34;_blank&#34;&gt;QGIS&lt;/a&gt; to subset the reliefs. Here&amp;rsquo;s a screencast of the process:&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/MAm1gqCGxc4&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;For the &lt;strong&gt;shapefiles&lt;/strong&gt;, sometimes it was simple to subset the &lt;code&gt;geom_sf()&lt;/code&gt; object via a column with island information (Hawaii, Maui, Oahu, Kauai) using &lt;code&gt;dplyr::filter()&lt;/code&gt;. However, when there was no information I also used &lt;a href=&#34;https://www.qgis.org/en/site/&#34; target=&#34;_blank&#34;&gt;QGIS&lt;/a&gt; to subset the &lt;strong&gt;shapefiles&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: I&amp;rsquo;m positive there is a way to do this via a bounding-box in &lt;code&gt;R&lt;/code&gt; I just never learned how&amp;hellip; please send me a message and I&amp;rsquo;ll update this if you know a way! Here&amp;rsquo;s a video of how I did it with QGIS:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/E805wtztzGA&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;br&gt;

![](https://www.youtube.com/watch?v=zNzZ1PfUDNk)

This project was a great learning experience not only for learning **Shiny &amp; Spatial Mapping**, but also learning a bit more about the development cycle of a &#34;*production*&#34;  applcation is like. It&#39;s kind of like the ol&#39; aphorism **&#34;Perfect is the eney of good&#34;** - you want to get your appltion out to the public ASAP. I released the app as soon as I had tested for bugs and thought the **UI** was *good-enough*.

&lt;br&gt;

After its release, I wanted to add a new feature - [Rayshader](https://www.rayshader.com/)!, Rayshader is one of the *hot-new* tools in [The Landscape of Spatial Data Analysis in R](https://nowosad.github.io/whyr_19/#1). Historically geographic information had always been presented in the form of two-dimensional maps, all the way from cave walls, parchment to computer screens. Because spatial information is inherently 3D, it makes sense that the tools available today is allowing 3D depictions of geographical data to [escape the realm of mere novelty](http://storymaps.esri.com/stories/2017/peaks-and-valleys/index.html?adumkts=branding&amp;aduc=print&amp;adum=interactive_pdf&amp;aduSF=url&amp;utm_Source=other&amp;aduca=m17the_arcgis_book_interactive_pdf&amp;aduco=peaks_and_valleys&amp;adut=storymap-87&amp;aducp=smartcommunities). With Rayshader you can control things like the lighting, camera tilt, and angle of view which provides an engaging experience for the audience.

&lt;br&gt;

I was signed up for [Tyler Morgan-Wall&#39;s (the developer of Rayshader)](https://www.tylermw.com/) **Penn State MUSA Masterclass: 3D Mapping and Visualization with R and Rayshader** next month (the awesome [talk is here](https://upenn.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ae6642b2-c2be-4ad0-846c-aafb00e00129) and the [Git repo is here](https://github.com/PennMUSA/MasterClass2019_3DMappingAndViz)) and wanted to spend a bit of time to demo the package before taking the class.

&lt;br&gt;

&gt; I came up with some very plain *&#34;desert&#34;*-y looking maps of Hawaii:

![](new-feature.gif)

&lt;br&gt;

Although I had wanted to allow the user to interact with the 3D maps, I ran into issues where the application attempted to use more memory then was avialable under the free-tier plan of [Shinyapps.io](https://www.shinyapps.io/). The [RStudio documentation on debugging your application](https://docs.rstudio.com/shinyapps.io/applications.html#debugging-your-application)&#39;s section on **Memory** wa useful for figuring this out as it suggests looking in the [application&#39;s logs](https://docs.rstudio.com/shinyapps.io/applications.html#logging) for `2019-11-18T15:12:16.088451+00:00 shinyapps[system]: Out of memory!`. I settled on providing the &#34;fly-by&#34; videos innstead.

After attending Tyler&#39;s class I wanted to update my application again by including a satellite overlay; I spent some time figuring out the best way to do this, modifying the easing function and `rayshader::render_movie()` parameters to make longer videos, testing it out, and then using `rsconnect::deployApp()` to re-deploy my application.

&lt;br&gt;

![](hawaii_vids.PNG)

&lt;br&gt;

I decided to merge all four videos together using [VSCD Video Editor](http://www.videosoftdev.com/) and overlaid some a musical track. Although Tyler promised Rayshader would have VR/AR capabilities in the near-future, I simply couldn&#39;t wait so I also made another version of the video with a steroscopic 3D effect for viewing with red and cyan anaglyph 3D glasses:

&lt;br&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/faCiHnL76Fw&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;future-directions-things-learned-general-musings&#34;&gt;Future Directions/Things Learned/General Musings&lt;/h3&gt;

&lt;p&gt;As&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not planning on developing this specific application any further as I&amp;rsquo;m quite happy with the final outcome. This project was mainly to learn:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shiny&lt;/li&gt;
&lt;li&gt;Spatial Mapping&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Software_release_life_cycle&#34; target=&#34;_blank&#34;&gt;Software release life cycles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From talking with my father he told me that software he worked on with IBM would be released with ~2000 known bugs.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Better a diamond with a flaw than a pebble without&amp;rdquo; - Confucius&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s &lt;a href=&#34;https://guides.github.com/features/issues/&#34; target=&#34;_blank&#34;&gt;important to keep track of tasks, enhancements, and bugs for your project&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;issues.png&#34; alt=&#34;Those scrupulous enough to peer into my repo will have found that I do not always follow my own advice...&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Now theoretically let&amp;rsquo;s say I was building this application for a client and they just &lt;strong&gt;had to have!&lt;/strong&gt; interactive 3D visualizations produced with Rayshader (something I&amp;rsquo;m not sure if Shiny is ideal for anyways) you could pay for a &lt;a href=&#34;https://www.shinyapps.io/&#34; target=&#34;_blank&#34;&gt;higher tier in Shinyapps.io&lt;/a&gt; to get a performance boost (&lt;em&gt;i.e.&lt;/em&gt; more RAM 🐏).&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Another thing that I may have wanted to do if my application was more complex is to provide the user with a tour using the {&lt;a href=&#34;https://github.com/JohnCoene/cicerone&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;cicerone&lt;/code&gt;&lt;/a&gt;} 📦 like what one sees on the &lt;a href=&#34;https://marionilab.cruk.cam.ac.uk/iSEE_allen&#34; target=&#34;_blank&#34;&gt;excellent tour of the iSEE Shiny interface&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;After &lt;strong&gt;75 commits&lt;/strong&gt; I&amp;rsquo;m pretty tired, so I didn&amp;rsquo;t include any code snippets here (BTW you can find all the code on Github). &lt;strong&gt;Full-disclosure&lt;/strong&gt;: the 75 commtis (and code) are currently split between two-repositories and I feel a bit of shame for that&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;shame.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;But there is a reason for this. I had intially started off the [mahalo] repository because I wanted to create package like the {[&lt;code&gt;bcmaps&lt;/code&gt;]()} 📦 but for Hawaii (I may still if there is enough interest from the community, but at the moment this is on-hold).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bcmaps.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Along with this, I also wanted to create a Showcase/Companion for the package with Shiny that would give users a run-through.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;I wasn&amp;rsquo;t sure what the &amp;ldquo;best practices&amp;rdquo; for this are: do you keep the app with the package or do you have a seperate repo? I reached out to &lt;a href=&#34;https://twitter.com/jdatap&#34; target=&#34;_blank&#34;&gt;John Coene (@jdatap)&lt;/a&gt;, because he&amp;rsquo;s an all-around nice guy (and also Swiss), and he suggested keeping them seperate if the application is large (adivce I followed) and to also use {&lt;a href=&#34;https://github.com/ThinkR-open/golem&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;golem&lt;/code&gt;&lt;/a&gt;} (advice which I did not follow - I still think it&amp;rsquo;s a great idea and I&amp;rsquo;ll consider for my next app though!).&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;I still need to spend some time figuring out how to supply datasets as I ran into issues with my project. I knew that I wouldn&amp;rsquo;t be able to just drop all of the shapefiles into my git repo because Github is meant for code and not data. I also knew that you could &lt;a href=&#34;https://www.r-bloggers.com/accelerating-ggplot2-use-a-canvas-to-speed-up-rendering-plots/&#34; target=&#34;_blank&#34;&gt;acclerate &lt;code&gt;ggplot2&lt;/code&gt; by using a canvas to speed up rendering plots&lt;/a&gt; so I thought to myself &amp;ldquo;If I&amp;rsquo;m just developing a map package I can generate &amp;ldquo;basemaps&amp;rdquo; as &lt;code&gt;.Rds&lt;/code&gt; objects and then use those in my [hinuhin repository]() to overlay other shapefiles on-top of&amp;rdquo;. Even though I avoided including most of the GIS information by producing these basemaps I had to set up a free account with &lt;a href=&#34;https://git-lfs.github.com/&#34; target=&#34;_blank&#34;&gt;Git Large File Storage&lt;/a&gt; to include the shapefiles I overlaid in this project and that took up &lt;strong&gt;80%&lt;/strong&gt; of my quota.&lt;/p&gt;

&lt;p&gt;One way I had heard of dealing with this was either by hosting on a server: either, an internal server (means the Shiny application can only be used within an organization and not the general public) or hosting the data on the cloud (&lt;em&gt;e.g.&lt;/em&gt; Amazon S3). Still other packages have dealt with this issue by accessing web-hosted databases via HTTP requests to APIs - which is well and good if the data is already available from an online database (it was not)&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;bcmaps&lt;/code&gt; package handels data in a way proposed by G. Brooke Anderson &amp;amp; &lt;a href=&#34;https://twitter.com/eddelbuettel&#34; target=&#34;_blank&#34;&gt;Dirk Eddelbuettel (@eddelbuettel)&lt;/a&gt;, via a &lt;a href=&#34;https://journal.r-project.org/archive/2017/RJ-2017-026/index.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;drat&lt;/code&gt; repository&lt;/a&gt; which allows a recommended maximum size of 1GB - I may have to look into this option if the Twitterverse is interested in a package for maps of Hawaii.&lt;/p&gt;

&lt;h3 id=&#34;brief-thought-on-the-future-of-rayshader&#34;&gt;Brief thought on the future of Rayshader&lt;/h3&gt;

&lt;p&gt;There are a number of companies today trying to map out city streets to create high-quality 3D maps for self-driving cars and projection projects (see: &lt;a href=&#34;https://www.fastcompany.com/90128298/the-race-to-map-the-world-in-3d&#34; target=&#34;_blank&#34;&gt;The Race to Map the World in 3D&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;street.gif&#34; alt=&#34;Image: Carmera&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Getting access to this kind of data would be awesome because it would mean you could overlay high-quality images over LIDAR like this one produced by Tyler of Philadelphia:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;phillyshadow3d-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you missed it at the top you can &lt;a href=&#34;https://matthew-j-oldach.shinyapps.io/hinuhinu&#34; target=&#34;_blank&#34;&gt;CLICK HERE TO GO TO MY SHINY APPLICATION DEPLOYMENT!!!&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>TensorFlow CNN for Fast Style Transfer</title>
      <link>/post/faststyletransfer/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/faststyletransfer/</guid>
      <description>

&lt;p&gt;Volcom was founded in 1991, it was the first company to combine skateboarding, surfing and snowboarding under one brand from it&amp;rsquo;s incepetion. I always loved how their aesthethics captured the energy and artistry of board-riding in its purest form.&lt;/p&gt;

&lt;p&gt;If you have no idea what I&amp;rsquo;m talking about here&amp;rsquo;s some samples from print advertisments and a clip from 2003&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=VGBQw46BbWA&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Big Youth Happening&lt;/strong&gt;&lt;/a&gt; which I would say was the ultimate inspiration for this post.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;volcom.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bigYouth.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Non-photorealistic rendering (&lt;a href=&#34;https://books.google.ca/books?id=YjXlTPFYGEYC&amp;amp;redir_esc=y&#34; target=&#34;_blank&#34;&gt;NPR&lt;/a&gt;) is a combination of computer graphics and computer vision that produces renderings in various artistic, expressive or stylized ways. A new art form that couldn&amp;rsquo;t have existed without computers. Researchers have proposed many algorithms and &lt;em&gt;styles&lt;/em&gt; such as painting, pen-and-ink drawing, tile mosaics, stippling, streamline visualization, and tensor field visualization. Although the details vary, the goal is to make an image look like some other image. Two main approaches to designing these algorithms exist. &lt;em&gt;Greedy algorithms&lt;/em&gt; greedily place strokes to match the target goas. &lt;em&gt;Optimization algorithms&lt;/em&gt; iteratively place and then adjust stroke positions to minimize the objective function. NPR can be done using a number of machine learning methods, most commonly &lt;a href=&#34;https://vimeo.com/302584040&#34; target=&#34;_blank&#34;&gt;General Adverserial Networks&lt;/a&gt; or &lt;a href=&#34;https://www.youtube.com/watch?v=UFffxcCQMPQ&#34; target=&#34;_blank&#34;&gt;Convolution Neural Networks&lt;/a&gt;(CNN) such as painting and drawing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;example.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I wanted to use &lt;a href=&#34;https://github.com/lengstrom/fast-style-transfer&#34; target=&#34;_blank&#34;&gt;lengstrom/fast-style-transfer&lt;/a&gt;, an &lt;em&gt;optimization technique&lt;/em&gt;, on a video of my friends and I backcountry skiing and snowboarding in The Rocky Mountains of Alberta.&lt;/p&gt;

&lt;p&gt;Fast-style-transfer is a TensorFlow CNN model based on a combination of &lt;a href=&#34;https://arxiv.org/abs/1508.06576&#34; target=&#34;_blank&#34;&gt;Gatys&amp;rsquo; A Neural Algorithm of Artistic Style&lt;/a&gt;, Johnson&amp;rsquo;s &lt;a href=&#34;http://cs.stanford.edu/people/jcjohns/eccv16/&#34; target=&#34;_blank&#34;&gt;Perceptual Losses for Real-Time Style Transfer and Super-Resolution&lt;/a&gt;, and Ulyanov&amp;rsquo;s &lt;a href=&#34;https://arxiv.org/abs/1607.08022&#34; target=&#34;_blank&#34;&gt;Instance Normalization&lt;/a&gt;. I&amp;rsquo;ll skip the details here because it&amp;rsquo;s been been far better described in the publications above (or in layman&amp;rsquo;s terms &lt;a href=&#34;https://towardsdatascience.com/a-journey-into-convolutional-neural-network-visualization-1abc71605209&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, and &lt;a href=&#34;https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;), suffice it to say it allows you to compose images/videos in the style of another image. Besides being fun it&amp;rsquo;s a nice visual way of showing the capabilities and internal representations of neural networks.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;fast-style-transfer&lt;/code&gt; repo comes with 6 trained models on famous paintings, allowing you to quikcly style your images (or videos) like them. But what&amp;rsquo;s the fun in doing what others have alread done?&lt;/p&gt;

&lt;p&gt;I wanted to see what kind of effect would be produced by training style transfer networks around interesting shapes and patterns! I selected a number patterns I thought would be interesting, for example animal patterns, fractals, fibonnaci sequences, a few vaporwave images (&lt;a href=&#34;https://github.com/moldach/vapoRwave&#34; target=&#34;_blank&#34;&gt;of course&lt;/a&gt;), and a bunch of images taken under a &lt;a href=&#34;https://en.wikipedia.org/wiki/Scanning_electron_microscope&#34; target=&#34;_blank&#34;&gt;SEM microscope&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;collage.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I then constructed a script to train 50 models simultaneously on a HPC (using a &lt;a href=&#34;https://images.nvidia.com/content/technologies/volta/pdf/tesla-volta-v100-datasheet-letter-fnl-web.pdf&#34; target=&#34;_blank&#34;&gt;GPU NVIDIA V100 Volta&lt;/a&gt;; a top-of-the-line $10,000 GPU - &lt;em&gt;spared no expense&lt;/em&gt;). After &lt;em&gt;many many&lt;/em&gt; hours of training, across hundreds of cores, I selected the 20 best (&lt;em&gt;i.e.&lt;/em&gt; most aesthetically pleasing) models to apply to the video.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mountains.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;The entire high-quality video can be found here&lt;/strong&gt;](&lt;a href=&#34;https://youtu.be/TuN4456PK-c&#34; target=&#34;_blank&#34;&gt;https://youtu.be/TuN4456PK-c&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&#34;technical-notes&#34;&gt;Technical Notes:&lt;/h3&gt;

&lt;p&gt;When training the models I noticed that the checkpoint files were being corrupted. I found a &lt;a href=&#34;https://github.com/lengstrom/fast-style-transfer/issues/78#issuecomment-302307215&#34; target=&#34;_blank&#34;&gt;closed issue on the repo: #78&lt;/a&gt; stating that Tensorflow&amp;rsquo;s Saver class was updated so you&amp;rsquo;ll need to change line 136 in &lt;code&gt;/src/optimize.py&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The script for training all of the networks on an HPC with a SLURM job scheduler is below, and can be run with &lt;code&gt;bash fastTrainer.bash &amp;lt;image_path&amp;gt; &amp;lt;out_path&amp;gt; &amp;lt;test_path&amp;gt;&lt;/code&gt;. Simply clone &lt;a href=&#34;https://github.com/lengstrom/fast-style-transfer&#34; target=&#34;_blank&#34;&gt;lengstrom/fast-style-transfer&lt;/a&gt; and create three folders inside. Create a sub-directory where you&amp;rsquo;ll put all the &lt;strong&gt;style images&lt;/strong&gt; you want to train, another sub-directory for the &lt;strong&gt;output&lt;/strong&gt; (&lt;code&gt;.ckpt&lt;/code&gt; files used to style your &lt;code&gt;.mp4&lt;/code&gt; videos), and a &lt;strong&gt;test&lt;/strong&gt; sub-directory for the model. As a default I used the &lt;code&gt;chicago&lt;/code&gt; for training and I&amp;rsquo;m not entirely sure if that makes a difference.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;!/bin/bash
#$ -pwd

# bash fastTrainer.bash /images/ /outpath/ /testpath/
##
## An embarrassingly parallel script to train many style transfer networks on a HPC
## Access to SLURM job scheduler and fast-style-transfer is required to run this program.
## The three mandatory pathways must be specified in the indicated order.

IMG=$(readlink -f &amp;quot;${1%/}&amp;quot;)     # path_to_train_images
OUT_DIR=$(readlink -f &amp;quot;${2%/}&amp;quot;)  # path_to_checkpoints
TEST=$(readlink -f &amp;quot;${3%/}&amp;quot;)  # path_to_tests

mkdir -p ${OUT_DIR}/jobs

JID=0   # job ID for SLURM job name

for f in ${IMG}/*; do

        let JID=(JID+1)

  cat &amp;gt; ${OUT_DIR}/jobs/style_${JID}.bash &amp;lt;&amp;lt; EOT # write job information for each job
#!/bin/bash
#SBATCH --gres=gpu:1        # request GPU
#SBATCH --cpus-per-task=2   # maximum CPU cores per GPU request
#SBATCH --time=00:01:00     # request 8 hours of walltime
#SBATCH --job-name=&amp;quot;fst_${JID}&amp;quot;
#SBATCH --output=${OUT_DIR}/jobs/%N-%j.out  # %N for node name, %j for jobID

### JOB SCRIPT BELLOW ###

# Load Modules
module load python/2.7.14
module load scipy-stack
source tensorflow/bin/activate

mkdir ${OUT_DIR}/${JID}
mkdir ${TEST}/${JID}

python style.py --style $f \
  --checkpoint-dir ${OUT_DIR}/${JID} \
  --test examples/content/chicago.jpg \
  --test-dir ${OUT_DIR}/${JID} \
  --content-weight 1.5e1 \
  --checkpoint-iterations 1000 \
  --batch-size 20

EOT
  chmod 754 $(readlink -f &amp;quot;${OUT_DIR}&amp;quot;)/jobs/style_${JID}.bash
  sbatch $(readlink -f &amp;quot;${OUT_DIR}&amp;quot;)/jobs/style_${JID}.bash
done

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;what-i-learned&#34;&gt;What I learned&lt;/h2&gt;

&lt;p&gt;Now &lt;a href=&#34;https://www.technologyreview.com/s/612913/a-philosopher-argues-that-an-ai-can-never-be-an-artist/&#34; target=&#34;_blank&#34;&gt;Sean Dorrance Kelly&lt;/a&gt; might argue I&amp;rsquo;m using the machines &amp;ldquo;creativity&amp;rdquo; as a subsititute for my own but I would disagree since there was a fair amount of creativity in selecting images to train models on and the editing itself. That being said an &lt;a href=&#34;https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx&#34; target=&#34;_blank&#34;&gt;AI generated work of art recently sold for $432,500 at Christie&amp;rsquo;s&lt;/a&gt; (the first auction house to offer a piece of art created by an algorithm).&lt;/p&gt;

&lt;p&gt;Besides the opportunity to exercise my right-brain, it was a good chance to gain some experience with tensorflow and python. This project was also illuminating because it made the hidden layers of networks more comprehensible by literally allowing me to &lt;em&gt;see&lt;/em&gt; how neural networks are performing!&lt;/p&gt;

&lt;p&gt;I think the field of &lt;strong&gt;Feature visualization&lt;/strong&gt; is exciting because it allows to peer behind the curtain and see how networks learn to classify images accurately. Take for example the &lt;a href=&#34;https://distill.pub/2019/activation-atlas/?utm_campaign=Data_Elixir&amp;amp;utm_medium=email&amp;amp;utm_source=Data_Elixir_224&#34; target=&#34;_blank&#34;&gt;Activation atlas&lt;/a&gt; which reveals visual abstractions within a model. It gives a global view of a dataset by showing feature visualization of averaged activation values from a neural network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;atlas.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As an analogy, while the 26 letters in the alphabet provide a basis for English, seeing how letters are commonly combined to make words gives far more insight into the concepts that can be expressed than the letters alone. Similarly, activation atlases give us a bigger picture view by showing common combinations of neurons.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In a perfect world the artist/user should have control over the decisions made by the algorithm. For example, to specify spatially varying styles to use, so that different rendering styles are used in different parts of the image, or to specify positions of individuial strokes. However, training these models is still too slow to be useful in an interactive application.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Step aside Cron, this is a job for .Rprofile &amp; logfiles!</title>
      <link>/post/rprofile/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/rprofile/</guid>
      <description>

&lt;p&gt;Just as &lt;a href=&#34;https://github.com/r-lib/testthat&#34; target=&#34;_blank&#34;&gt;test automation&lt;/a&gt; is a critical part of &lt;a href=&#34;http://users.atw.hu/sustainsoftdev/ch05lev1sec2.html&#34; target=&#34;_blank&#34;&gt;rutheless testing&lt;/a&gt;, your goal for any project should be to identify taks that can be automated (and do it!).&lt;/p&gt;

&lt;p&gt;There are a number of packages that allow you to schedule R scripts at specific times; two that come to mind are &lt;a href=&#34;https://cran.r-project.org/package=taskscheduleR&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;taskscheduleR&lt;/code&gt;&lt;/a&gt; (for Windows) and &lt;a href=&#34;https://cran.r-project.org/package=cronR&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;cronR&lt;/code&gt;&lt;/a&gt; (for Unix/Linux). We have &lt;code&gt;cronR&lt;/code&gt; setup on RStudio server at work, and it has a nice &lt;em&gt;RStudio addin&lt;/em&gt; which allows us to schedule tasks around any complex schedule. You can use these kind of tools &lt;a href=&#34;http://www.r-datacollection.com/blog/Welcome-to-the-ADCR-Blog/&#34; target=&#34;_blank&#34;&gt;to automate data collections&lt;/a&gt;, &lt;a href=&#34;http://www.r-datacollection.com/blog/Welcome-to-the-ADCR-Blog/&#34; target=&#34;_blank&#34;&gt;automate markdown reports to e-mail&lt;/a&gt;, &lt;a href=&#34;http://www.r-datacollection.com/blog/Welcome-to-the-ADCR-Blog/&#34; target=&#34;_blank&#34;&gt;or even the weather&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Alternatively, when you want a function (or script) to launch every time you start &lt;code&gt;R&lt;/code&gt; you can place these inside &lt;code&gt;.Rprofile&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;But what about if you want a function to start only the first time a user logs in? This could be something simple (like a reminder) to fill in a progress report, or in this case a bit of &lt;em&gt;Monday Morning (de)Motivation&lt;/em&gt;. This is a job for logfiles!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s be straight here, I love Mondays (because &lt;a href=&#34;https://rweekly.org/&#34; target=&#34;_blank&#34;&gt;rweekly&lt;/a&gt; is released!), but most people don&amp;rsquo;t! Therefore, I made a &lt;code&gt;.csv&lt;/code&gt; file of &lt;code&gt;178&lt;/code&gt; quotes about Monday and a folder of 83 &lt;code&gt;.png&lt;/code&gt; images of cartoon characters sleeping. I used the &lt;code&gt;.First()&lt;/code&gt; function in &lt;code&gt;.Rprofile&lt;/code&gt; to create a logfile (if one doesn&amp;rsquo;t already exist) and randomly pair an image with a quote the first time a user logs in on Monday morning (using the &lt;code&gt;advicegiveR&lt;/code&gt; package).
Here&amp;rsquo;s some examples of images a user might see first thing Monday morning:&lt;/p&gt;

&lt;h3 id=&#34;the-good&#34;&gt;The Good&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;fig1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-bad&#34;&gt;The Bad&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;fig2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-ugly&#34;&gt;The Ugly&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;fig3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Any other time of that day (or any other day of the week) it will simply call a sage piece of collected advice from the &lt;code&gt;R-help&lt;/code&gt; forum via the &lt;code&gt;fortunes&lt;/code&gt; package. An example:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;R will always be arcane to those who do not make a serious effort to learn it. It is &lt;strong&gt;not&lt;/strong&gt; meant to be
intuitive and easy for casual users to just plunge into. It is far too complex and powerful for that. But
the rewards are great for serious data analysts who put in the effort.
   &amp;ndash; Berton Gunter
      R-help (August 2007)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You need to create a folder in your home directory that contains a &lt;code&gt;quotes.csv&lt;/code&gt;, a &lt;code&gt;LogFile.txt&lt;/code&gt; and &lt;code&gt;images&lt;/code&gt; folder.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;.First &amp;lt;- function(){
        today &amp;lt;- as.Date(Sys.Date())
        LastLog &amp;lt;- &amp;quot;&amp;quot;
        if(file.exists(&amp;quot;~/iHateMondays/LogFile.txt&amp;quot;)) {
                LogFile &amp;lt;- file(&amp;quot;~/iHateMondays/LogFile.txt&amp;quot;, open=&amp;quot;r&amp;quot;)
                LastLog &amp;lt;- readLines(LogFile, 1L)
                close(LogFile)
        }
        LogFile &amp;lt;- file(&amp;quot;~/iHateMondays/LogFile.txt&amp;quot;, open=&amp;quot;w&amp;quot;)
        writeLines(as.character(today), LogFile)
        close(LogFile)
        
        if(LastLog == as.character(today)) {
                # Already logged on today, just exit
                return()
        }
        
        ## If you get here, Need to run the first login code
        DOW &amp;lt;- weekdays(today)
        if (DOW == &amp;quot;Monday&amp;quot;) {
                # I Hate Mondays!
                suppressWarnings(library(advicegiveR, warn.conflicts = FALSE))
                suppressWarnings(library(readr, warn.conflicts = FALSE))
                quotes &amp;lt;- read_csv(&amp;quot;~/iHateMondays/quotes.csv&amp;quot;, col_names = FALSE)
                x1 &amp;lt;- sample(1:nrow(quotes), 1)
                advice &amp;lt;- as.character(quotes[x1,])
                y &amp;lt;- list.files(&amp;quot;~/iHateMondays/images&amp;quot;)
                # select one randomly
                y1 &amp;lt;- sample(1:length(y), 1)
                image &amp;lt;- magick::image_read(paste0(&amp;quot;~/iHateMondays/images&amp;quot;, y[y1]))
                # print image
                advicegiveR::print_advice(image = image, advice = advice, textcolor = &amp;quot;yellow&amp;quot;, size = 40)
        } else {
                # Fortune
                suppressWarnings(library(fortunes, warn.conflicts = FALSE))
                rnum &amp;lt;- sample(1:386, 1)
                print(fortune(rnum))
        }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now Ideally, you should use a contrasting border around the inner text color to make it readable on any background.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;fig4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/leeper/meme&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;meme&lt;/code&gt; R package&lt;/a&gt; package uses a black border around text and positions text like a typical meme (top &amp;amp; bottom).&lt;/p&gt;

&lt;p&gt;By including a simple helper function to split the quote into equal lengthed top/bottom sections, the code would look like this:&lt;/p&gt;

&lt;style&gt;
pre.bluecars {
    background-color: #aabbff !important;
}
pre.redcars {
    background-color: #ffbbbb !important;
}
&lt;/style&gt;

&lt;pre&gt;&lt;code class=&#34;language-bluecars&#34;&gt;suppressWarnings(library(tidyverse))
word_split &amp;lt;- function(x, side=&amp;quot;left&amp;quot;, sep=&amp;quot; &amp;quot;) {
  words &amp;lt;- strsplit(as.character(x), sep)
  nwords &amp;lt;- lengths(words)
  if(side==&amp;quot;left&amp;quot;) {
    start &amp;lt;- 1
    end &amp;lt;- ceiling(nwords/2)
  } else if (side==&amp;quot;right&amp;quot;) {
    start &amp;lt;- ceiling((nwords+2)/2)
    end &amp;lt;- nwords
  }
  cw &amp;lt;- function(words, start, stop) paste(words[start:stop], collapse=sep)
  pmap_chr(list(words, start, end), cw)
}
left_words &amp;lt;- function(..., side) word_split(..., side=&amp;quot;left&amp;quot;)
right_words &amp;lt;- function(..., side) word_split(..., side=&amp;quot;right&amp;quot;)

.First &amp;lt;- function(){
        today &amp;lt;- as.Date(Sys.Date())
        LastLog &amp;lt;- &amp;quot;&amp;quot;
        if(file.exists(&amp;quot;~/iHateMondays/LogFile.txt&amp;quot;)) {
                LogFile &amp;lt;- file(&amp;quot;~/iHateMondays/LogFile.txt&amp;quot;, open=&amp;quot;r&amp;quot;)
                LastLog &amp;lt;- readLines(LogFile, 1L)
                close(LogFile)
        }
        LogFile &amp;lt;- file(&amp;quot;~/iHateMondays/LogFile.txt&amp;quot;, open=&amp;quot;w&amp;quot;)
        writeLines(as.character(today), LogFile)
        close(LogFile)

        if(LastLog == as.character(today)) {
                # Already logged on today, just exit
                return()
        }

        ## If you get here, Need to run the first login code
        DOW &amp;lt;- weekdays(today)
        if (DOW == &amp;quot;Monday&amp;quot;) {
                # I Hate Mondays!
                suppressWarnings(library(readr, warn.conflicts = FALSE))
                suppressWarnings(library(meme, warn.conflicts = FALSE))
                quotes &amp;lt;- read_csv(&amp;quot;~/iHateMondays/quotes.csv&amp;quot;, col_names = FALSE)
                x1 &amp;lt;- sample(1:nrow(quotes), 1)
                advice &amp;lt;- as.character(quotes[x1,])
                top_words &amp;lt;- left_words(advice)
                bottom_words &amp;lt;- right_words(advice)
                y &amp;lt;- list.files(&amp;quot;~/iHateMondays/images&amp;quot;)
                # select one randomly
                y1 &amp;lt;- sample(1:length(y), 1)
                image &amp;lt;- magick::image_read(paste0(&amp;quot;~/iHateMondays/images/&amp;quot;, y[y1]))
                # print image
                meme(paste0(&amp;quot;~/iHateMondays/images/&amp;quot;, y[y1]), size = &amp;quot;1.5&amp;quot;, upper = top_words, lower = bottom_words, color = &amp;quot;yellow&amp;quot;, font = &amp;quot;Times&amp;quot;)

        } else {
                # Fortune
                suppressWarnings(library(fortunes, warn.conflicts = FALSE))
                rnum &amp;lt;- sample(1:386, 1)
                print(fortune(rnum))
        }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;fig5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image-grid with Ninjutsu CSS theme in Xaringan</title>
      <link>/post/ninjutsu/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/ninjutsu/</guid>
      <description>&lt;p&gt;A graduate student in our laboratory recently asked me if it was possible to include more than two images, side-by-side, in &lt;code&gt;Xaringan&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Of course anything is possible, however, most blog posts only touch on the most basic things you can do. With custom &lt;code&gt;CSS&lt;/code&gt; you can do whatever you want. I wanted to create an image-grid of a bunch of GIFs so I used the &lt;code&gt;ninjutsu&lt;/code&gt; theme to accomplish it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/4EFfHjHbgUnhzeZtg0/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://moldach.github.io/xaringan-presentation_ninjutsu/&#34; target=&#34;_blank&#34;&gt;Link to the slide-show&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started with Drake in R</title>
      <link>/post/drake/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/drake/</guid>
      <description>&lt;p&gt;Recently I got interested in using the &lt;code&gt;xaringan&lt;/code&gt; package for creating HTML based R Markdown documents because I could use the &lt;code&gt;widgetframe&lt;/code&gt; package to embed &lt;code&gt;htmlwidgets&lt;/code&gt; as responsive iframes (I had created some spinning 3D visulizations with pseudo-coloring I wanted to present interactively).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;xaringan&lt;/code&gt;, it&amp;rsquo;s a &lt;code&gt;R&lt;/code&gt; pacakges for creating slideshows with &lt;a href=&#34;http://remarkjs.com/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;remark.js&lt;/code&gt;&lt;/a&gt; through R Markdown.&lt;/p&gt;

&lt;p&gt;Around the same time I learnt about &lt;a href=&#34;https://github.com/ropensci/drake&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;Drake&lt;/code&gt;&lt;/a&gt; (or &amp;ldquo;Data Frames in R for Make&amp;rdquo;) which is an amazing a time-saving reproducible build system for data scientist specifically tailored to &lt;code&gt;R&lt;/code&gt;. The pacakge makes use of the &lt;code&gt;futures&lt;/code&gt; package allowing the use of parallel computing on high-performance computing systems.&lt;/p&gt;

&lt;p&gt;I recently gave a talk at the Douglas Mental Health University Institute talking about the advantages of Drake (and a few other interesting projects).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/3fhu1Pm9kYB5RgDtn7/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The slides can be found &lt;a href=&#34;https://moldach.github.io/xaringan-presentation_drake/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Web Scraping Google Sheets with RSelenium</title>
      <link>/project/rselenium/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 -0500</pubDate>
      
      <guid>/project/rselenium/</guid>
      <description></description>
    </item>
    
    <item>
      <title>10 Tips for Choosing the Optimal Number of Clusters</title>
      <link>/project/optimal-clustering/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 -0500</pubDate>
      
      <guid>/project/optimal-clustering/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Gamification of Fitbit: How An API Provided The Next Level of tRaining</title>
      <link>/project/fitbit-project/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 -0500</pubDate>
      
      <guid>/project/fitbit-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to Highlight 3D Brain Regions</title>
      <link>/project/3d-brain/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/project/3d-brain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Transcriptome Assembly and Annotation</title>
      <link>/project/assembly/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/project/assembly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>vapoRwave ggplot2 themes &amp; palettes</title>
      <link>/project/vaporwave/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/project/vaporwave/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to Choose the Best Open Source Software</title>
      <link>/project/software-solutions/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/project/software-solutions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reversing the order of axis in a ggplot2 scatterplot</title>
      <link>/project/reverse-axis/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/project/reverse-axis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Gold Standard for Data Science Project Management</title>
      <link>/project/project-management/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/project/project-management/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0400</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
